{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_directory: /home/kenny/Projects/kaggle/isic2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6617/593140677.py:179: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta = pd.read_csv(PATHS.train_metadata_path)[[\"isic_id\",\"patient_id\",\"target\"]]\n",
      "/tmp/ipykernel_6617/593140677.py:182: DtypeWarning: Columns (8,13,16,17,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta_ext = pd.read_csv(PATHS.train_metadata_path_ext)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go to here 2686\n",
      "df  (3828, 6)\n",
      "go to here 1334\n",
      "df  (3828, 6)\n",
      "go to here 2027\n",
      "df  (3828, 6)\n",
      "go to here 3239\n",
      "df  (3828, 6)\n",
      "go to here 274\n",
      "df  (3828, 6)\n",
      "go to here 3360\n",
      "df  (3828, 6)\n",
      "go to here 3496\n",
      "df  (3828, 6)\n",
      "go to here 847\n",
      "df  (3828, 6)\n",
      "go to here 2029\n",
      "df  (3828, 6)\n",
      "go to here 3044\n",
      "df  (3828, 6)\n",
      "go to here 1054\n",
      "df  (3828, 6)\n",
      "go to here 2615\n",
      "df  (3828, 6)\n",
      "go to here 1815\n",
      "df  (3828, 6)\n",
      "go to here 1454\n",
      "df  (3828, 6)\n",
      "go to here 2523\n",
      "df  (3828, 6)\n",
      "go to here 3497\n",
      "df  (3828, 6)\n",
      "go to here 2605\n",
      "df  (3828, 6)\n",
      "go to here 3262\n",
      "df  (3828, 6)\n",
      "go to here 2237\n",
      "df  (3828, 6)\n",
      "go to here 1801\n",
      "df  (3828, 6)\n",
      "go to here 167\n",
      "df  (3828, 6)\n",
      "go to here 2900\n",
      "df  (3828, 6)\n",
      "go to here 2513\n",
      "df  (3828, 6)\n",
      "go to here 3119\n",
      "df  (3828, 6)\n",
      "go to here 1714\n",
      "df  (3828, 6)\n",
      "go to here 97\n",
      "df  (3828, 6)\n",
      "go to here 133\n",
      "df  (3828, 6)\n",
      "go to here 1336\n",
      "df  (3828, 6)\n",
      "go to here 3722\n",
      "df  (3828, 6)\n",
      "go to here 3093\n",
      "df  (3828, 6)\n",
      "go to here 1854\n",
      "df  (3828, 6)\n",
      "go to here 1832\n",
      "df  (3828, 6)\n",
      "go to here 2076\n",
      "df  (3828, 6)\n",
      "go to here 2193\n",
      "df  (3828, 6)\n",
      "go to here 3826\n",
      "df  (3828, 6)\n",
      "go to here 2302\n",
      "df  (3828, 6)\n",
      "go to here 1707\n",
      "df  (3828, 6)\n",
      "go to here 1559\n",
      "df  (3828, 6)\n",
      "go to here 2961\n",
      "df  (3828, 6)\n",
      "go to here 2471\n",
      "df  (3828, 6)\n",
      "go to here 1819\n",
      "df  (3828, 6)\n",
      "go to here 3740\n",
      "df  (3828, 6)\n",
      "go to here 756\n",
      "df  (3828, 6)\n",
      "go to here 3078\n",
      "df  (3828, 6)\n",
      "go to here 3033\n",
      "df  (3828, 6)\n",
      "go to here 3477\n",
      "df  (3828, 6)\n",
      "go to here 3331\n",
      "df  (3828, 6)\n",
      "go to here 3619\n",
      "df  (3828, 6)\n",
      "go to here 3729\n",
      "df  (3828, 6)\n",
      "go to here 559\n",
      "df  (3828, 6)\n",
      "go to here 884\n",
      "df  (3828, 6)\n",
      "go to here 2657\n",
      "df  (3828, 6)\n",
      "go to here 501\n",
      "df  (3828, 6)\n",
      "go to here 1683\n",
      "df  (3828, 6)\n",
      "go to here 14\n",
      "df  (3828, 6)\n",
      "go to here 3014\n",
      "df  (3828, 6)\n",
      "go to here 493\n",
      "df  (3828, 6)\n",
      "go to here 3733\n",
      "df  (3828, 6)\n",
      "go to here 3228\n",
      "df  (3828, 6)\n",
      "go to here 597\n",
      "df  (3828, 6)\n",
      "go to here 2431\n",
      "df  (3828, 6)\n",
      "go to here 3663\n",
      "df  (3828, 6)\n",
      "go to here 698\n",
      "df  (3828, 6)\n",
      "go to here 2291\n",
      "df  (3828, 6)\n",
      "go to here 87\n",
      "df  (3828, 6)\n",
      "go to here 1835\n",
      "df  (3828, 6)\n",
      "go to here 1690\n",
      "df  (3828, 6)\n",
      "go to here 3696\n",
      "df  (3828, 6)\n",
      "go to here 1958\n",
      "df  (3828, 6)\n",
      "go to here 3538\n",
      "df  (3828, 6)\n",
      "go to here 1445\n",
      "df  (3828, 6)\n",
      "go to here 3703\n",
      "df  (3828, 6)\n",
      "go to here 2181\n",
      "df  (3828, 6)\n",
      "go to here 3488\n",
      "df  (3828, 6)\n",
      "go to here 2110\n",
      "df  (3828, 6)\n",
      "go to here 2334\n",
      "df  (3828, 6)\n",
      "go to here 1846\n",
      "df  (3828, 6)\n",
      "go to here 2810\n",
      "df  (3828, 6)\n",
      "go to here 2435\n",
      "df  (3828, 6)\n",
      "go to here 47\n",
      "df  (3828, 6)\n",
      "go to here 775\n",
      "df  (3828, 6)\n",
      "go to here 2028\n",
      "df  (3828, 6)\n",
      "go to here 1115\n",
      "df  (3828, 6)\n",
      "go to here 750\n",
      "df  (3828, 6)\n",
      "go to here 1320\n",
      "df  (3828, 6)\n",
      "go to here 673\n",
      "df  (3828, 6)\n",
      "go to here 808\n",
      "df  (3828, 6)\n",
      "go to here 300\n",
      "df  (3828, 6)\n",
      "go to here 1262\n",
      "df  (3828, 6)\n",
      "go to here 799\n",
      "df  (3828, 6)\n",
      "go to here 1786\n",
      "df  (3828, 6)\n",
      "go to here 1229\n",
      "df  (3828, 6)\n",
      "go to here 3139\n",
      "df  (3828, 6)\n",
      "go to here 1482\n",
      "df  (3828, 6)\n",
      "go to here 1982\n",
      "df  (3828, 6)\n",
      "go to here 3687\n",
      "df  (3828, 6)\n",
      "go to here 3125\n",
      "df  (3828, 6)\n",
      "go to here 1796\n",
      "df  (3828, 6)\n",
      "go to here 1044\n",
      "df  (3828, 6)\n",
      "go to here 2406\n",
      "df  (3828, 6)\n",
      "go to here 2452\n",
      "df  (3828, 6)\n",
      "go to here 1452\n",
      "df  (3828, 6)\n",
      "go to here 3494\n",
      "df  (3828, 6)\n",
      "go to here 1113\n",
      "df  (3828, 6)\n",
      "go to here 1526\n",
      "df  (3828, 6)\n",
      "go to here 1143\n",
      "df  (3828, 6)\n",
      "go to here 2175\n",
      "df  (3828, 6)\n",
      "go to here 2864\n",
      "df  (3828, 6)\n",
      "go to here 3017\n",
      "df  (3828, 6)\n",
      "go to here 3400\n",
      "df  (3828, 6)\n",
      "go to here 2053\n",
      "df  (3828, 6)\n",
      "go to here 3184\n",
      "df  (3828, 6)\n",
      "go to here 2099\n",
      "df  (3828, 6)\n",
      "go to here 2107\n",
      "df  (3828, 6)\n",
      "go to here 3104\n",
      "df  (3828, 6)\n",
      "go to here 3164\n",
      "df  (3828, 6)\n",
      "go to here 3294\n",
      "df  (3828, 6)\n",
      "go to here 1976\n",
      "df  (3828, 6)\n",
      "go to here 2502\n",
      "df  (3828, 6)\n",
      "go to here 2735\n",
      "df  (3828, 6)\n",
      "go to here 3365\n",
      "df  (3828, 6)\n",
      "go to here 636\n",
      "df  (3828, 6)\n",
      "go to here 3800\n",
      "df  (3828, 6)\n",
      "go to here 1037\n",
      "df  (3828, 6)\n",
      "go to here 3097\n",
      "df  (3828, 6)\n",
      "go to here 2908\n",
      "df  (3828, 6)\n",
      "go to here 1136\n",
      "df  (3828, 6)\n",
      "go to here 77\n",
      "df  (3828, 6)\n",
      "go to here 1697\n",
      "df  (3828, 6)\n",
      "go to here 2669\n",
      "df  (3828, 6)\n",
      "go to here 2967\n",
      "df  (3828, 6)\n",
      "go to here 3475\n",
      "df  (3828, 6)\n",
      "go to here 659\n",
      "df  (3828, 6)\n",
      "go to here 1447\n",
      "df  (3828, 6)\n",
      "go to here 1654\n",
      "df  (3828, 6)\n",
      "go to here 3700\n",
      "df  (3828, 6)\n",
      "go to here 732\n",
      "df  (3828, 6)\n",
      "go to here 1869\n",
      "df  (3828, 6)\n",
      "go to here 390\n",
      "df  (3828, 6)\n",
      "go to here 1126\n",
      "df  (3828, 6)\n",
      "go to here 985\n",
      "df  (3828, 6)\n",
      "go to here 1381\n",
      "df  (3828, 6)\n",
      "go to here 3534\n",
      "df  (3828, 6)\n",
      "go to here 3240\n",
      "df  (3828, 6)\n",
      "go to here 1965\n",
      "df  (3828, 6)\n",
      "go to here 2898\n",
      "df  (3828, 6)\n",
      "go to here 1053\n",
      "df  (3828, 6)\n",
      "go to here 912\n",
      "df  (3828, 6)\n",
      "go to here 39\n",
      "df  (3828, 6)\n",
      "go to here 521\n",
      "df  (3828, 6)\n",
      "go to here 3201\n",
      "df  (3828, 6)\n",
      "go to here 2988\n",
      "df  (3828, 6)\n",
      "go to here 3073\n",
      "df  (3828, 6)\n",
      "go to here 3408\n",
      "df  (3828, 6)\n",
      "go to here 2809\n",
      "df  (3828, 6)\n",
      "go to here 2009\n",
      "df  (3828, 6)\n",
      "go to here 1927\n",
      "df  (3828, 6)\n",
      "go to here 3180\n",
      "df  (3828, 6)\n",
      "go to here 2140\n",
      "df  (3828, 6)\n",
      "go to here 3040\n",
      "df  (3828, 6)\n",
      "go to here 1763\n",
      "df  (3828, 6)\n",
      "go to here 878\n",
      "df  (3828, 6)\n",
      "go to here 815\n",
      "df  (3828, 6)\n",
      "go to here 2632\n",
      "df  (3828, 6)\n",
      "go to here 3803\n",
      "df  (3828, 6)\n",
      "go to here 812\n",
      "df  (3828, 6)\n",
      "go to here 1314\n",
      "df  (3828, 6)\n",
      "go to here 3547\n",
      "df  (3828, 6)\n",
      "go to here 3419\n",
      "df  (3828, 6)\n",
      "go to here 1185\n",
      "df  (3828, 6)\n",
      "go to here 67\n",
      "df  (3828, 6)\n",
      "go to here 2389\n",
      "df  (3828, 6)\n",
      "go to here 2952\n",
      "df  (3828, 6)\n",
      "go to here 402\n",
      "df  (3828, 6)\n",
      "go to here 545\n",
      "df  (3828, 6)\n",
      "go to here 355\n",
      "df  (3828, 6)\n",
      "go to here 3616\n",
      "df  (3828, 6)\n",
      "go to here 2118\n",
      "df  (3828, 6)\n",
      "go to here 2189\n",
      "df  (3828, 6)\n",
      "go to here 1864\n",
      "df  (3828, 6)\n",
      "go to here 1827\n",
      "df  (3828, 6)\n",
      "go to here 787\n",
      "df  (3828, 6)\n",
      "go to here 1912\n",
      "df  (3828, 6)\n",
      "go to here 286\n",
      "df  (3828, 6)\n",
      "go to here 3058\n",
      "df  (3828, 6)\n",
      "go to here 1244\n",
      "df  (3828, 6)\n",
      "go to here 3295\n",
      "df  (3828, 6)\n",
      "go to here 2535\n",
      "df  (3828, 6)\n",
      "go to here 254\n",
      "df  (3828, 6)\n",
      "go to here 2477\n",
      "df  (3828, 6)\n",
      "go to here 1586\n",
      "df  (3828, 6)\n",
      "go to here 1370\n",
      "df  (3828, 6)\n",
      "go to here 1957\n",
      "df  (3828, 6)\n",
      "go to here 2939\n",
      "df  (3828, 6)\n",
      "go to here 3559\n",
      "df  (3828, 6)\n",
      "go to here 3064\n",
      "df  (3828, 6)\n",
      "go to here 424\n",
      "df  (3828, 6)\n",
      "go to here 1167\n",
      "df  (3828, 6)\n",
      "go to here 2084\n",
      "df  (3828, 6)\n",
      "go to here 3089\n",
      "df  (3828, 6)\n",
      "go to here 184\n",
      "df  (3828, 6)\n",
      "go to here 483\n",
      "df  (3828, 6)\n",
      "go to here 1090\n",
      "df  (3828, 6)\n",
      "go to here 3706\n",
      "df  (3828, 6)\n",
      "go to here 2544\n",
      "df  (3828, 6)\n",
      "go to here 3415\n",
      "df  (3828, 6)\n",
      "go to here 2039\n",
      "df  (3828, 6)\n",
      "go to here 3670\n",
      "df  (3828, 6)\n",
      "go to here 1249\n",
      "df  (3828, 6)\n",
      "go to here 510\n",
      "df  (3828, 6)\n",
      "go to here 3323\n",
      "df  (3828, 6)\n",
      "go to here 701\n",
      "df  (3828, 6)\n",
      "go to here 1439\n",
      "df  (3828, 6)\n",
      "go to here 405\n",
      "df  (3828, 6)\n",
      "go to here 3618\n",
      "df  (3828, 6)\n",
      "go to here 1443\n",
      "df  (3828, 6)\n",
      "go to here 194\n",
      "df  (3828, 6)\n",
      "go to here 2929\n",
      "df  (3828, 6)\n",
      "go to here 1121\n",
      "df  (3828, 6)\n",
      "go to here 2889\n",
      "df  (3828, 6)\n",
      "go to here 1687\n",
      "df  (3828, 6)\n",
      "go to here 714\n",
      "df  (3828, 6)\n",
      "go to here 3160\n",
      "df  (3828, 6)\n",
      "go to here 3378\n",
      "df  (3828, 6)\n",
      "go to here 3675\n",
      "df  (3828, 6)\n",
      "go to here 1350\n",
      "df  (3828, 6)\n",
      "go to here 3617\n",
      "df  (3828, 6)\n",
      "go to here 3464\n",
      "df  (3828, 6)\n",
      "go to here 899\n",
      "df  (3828, 6)\n",
      "go to here 2627\n",
      "df  (3828, 6)\n",
      "go to here 2062\n",
      "df  (3828, 6)\n",
      "go to here 2994\n",
      "df  (3828, 6)\n",
      "go to here 2035\n",
      "df  (3828, 6)\n",
      "go to here 3265\n",
      "df  (3828, 6)\n",
      "go to here 181\n",
      "df  (3828, 6)\n",
      "go to here 3801\n",
      "df  (3828, 6)\n",
      "go to here 3411\n",
      "df  (3828, 6)\n",
      "go to here 2026\n",
      "df  (3828, 6)\n",
      "go to here 1807\n",
      "df  (3828, 6)\n",
      "go to here 919\n",
      "df  (3828, 6)\n",
      "go to here 2743\n",
      "df  (3828, 6)\n",
      "go to here 50\n",
      "df  (3828, 6)\n",
      "go to here 2255\n",
      "df  (3828, 6)\n",
      "go to here 2124\n",
      "df  (3828, 6)\n",
      "go to here 1921\n",
      "df  (3828, 6)\n",
      "go to here 1742\n",
      "df  (3828, 6)\n",
      "go to here 3824\n",
      "df  (3828, 6)\n",
      "go to here 2546\n",
      "df  (3828, 6)\n",
      "go to here 3455\n",
      "df  (3828, 6)\n",
      "go to here 1716\n",
      "df  (3828, 6)\n",
      "go to here 86\n",
      "df  (3828, 6)\n",
      "go to here 2352\n",
      "df  (3828, 6)\n",
      "go to here 2597\n",
      "df  (3828, 6)\n",
      "go to here 616\n",
      "df  (3828, 6)\n",
      "go to here 2000\n",
      "df  (3828, 6)\n",
      "go to here 2965\n",
      "df  (3828, 6)\n",
      "go to here 2729\n",
      "df  (3828, 6)\n",
      "go to here 520\n",
      "df  (3828, 6)\n",
      "go to here 107\n",
      "df  (3828, 6)\n",
      "go to here 1933\n",
      "df  (3828, 6)\n",
      "go to here 2616\n",
      "df  (3828, 6)\n",
      "go to here 1850\n",
      "df  (3828, 6)\n",
      "go to here 381\n",
      "df  (3828, 6)\n",
      "go to here 723\n",
      "df  (3828, 6)\n",
      "go to here 227\n",
      "df  (3828, 6)\n",
      "go to here 1354\n",
      "df  (3828, 6)\n",
      "go to here 2167\n",
      "df  (3828, 6)\n",
      "go to here 2036\n",
      "df  (3828, 6)\n",
      "go to here 3340\n",
      "df  (3828, 6)\n",
      "go to here 3599\n",
      "df  (3828, 6)\n",
      "go to here 1741\n",
      "df  (3828, 6)\n",
      "go to here 3190\n",
      "df  (3828, 6)\n",
      "go to here 2040\n",
      "df  (3828, 6)\n",
      "go to here 1862\n",
      "df  (3828, 6)\n",
      "go to here 2266\n",
      "df  (3828, 6)\n",
      "go to here 1944\n",
      "df  (3828, 6)\n",
      "go to here 1300\n",
      "df  (3828, 6)\n",
      "go to here 2664\n",
      "df  (3828, 6)\n",
      "go to here 437\n",
      "df  (3828, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=346'>347</a>\u001b[0m best_val_loss, best_val_pauc \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, \u001b[39m0\u001b[39m        \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=347'>348</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m30\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=348'>349</a>\u001b[0m     train_loss, train_pauc \u001b[39m=\u001b[39m train(model, train_loader, optimizer, criterion)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=349'>350</a>\u001b[0m     val_loss, val_pauc, all_probs, all_targets \u001b[39m=\u001b[39m val(model, val_loader, criterion)        \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=350'>351</a>\u001b[0m     \u001b[39mif\u001b[39;00m val_pauc \u001b[39m>\u001b[39m best_val_pauc:\n",
      "\u001b[1;32m/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=201'>202</a>\u001b[0m all_probs \u001b[39m=\u001b[39m []        \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=203'>204</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m \u001b[39minput\u001b[39;49m,_, targets \u001b[39min\u001b[39;49;00m train_loader:        \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=205'>206</a>\u001b[0m     \u001b[39minput\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m     targets \u001b[39m=\u001b[39;49m targets\u001b[39m.\u001b[39;49mto(DEVICE)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# print(f\"isic_id {isic_id}. target {target}, path {img_path}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)            \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#W4sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/PIL/Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mBGR;15\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBGR;16\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBGR;24\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    993\u001b[0m     deprecate(mode, \u001b[39m12\u001b[39m)\n\u001b[0;32m--> 995\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    997\u001b[0m has_transparency \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\n\u001b[1;32m    998\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    999\u001b[0m     \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from matplotlib import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import gc\n",
    "\n",
    "PRO_DIR = r\"/home/kenny/Projects/kaggle/isic2024\"\n",
    "os.chdir(PRO_DIR)\n",
    "print(\"project_directory:\", PRO_DIR)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_meta , undersample_rate=2, transform=None, n=\"all\"):   \n",
    "        df_meta = df_meta.reset_index(drop=True)  # Reset the index\n",
    "        file_list = {}\n",
    "        for _, row in df_meta.iterrows():        \n",
    "            if row[\"set\"]==\"org\":\n",
    "                file_list[row[\"isic_id\"]] = f\"{PRO_DIR}/input/train-image/image/{row['isic_id']}.jpg\"\n",
    "            else:\n",
    "                file_list[row[\"isic_id\"]] = f\"{PRO_DIR}/data/external/{row['isic_id']}.jpg\"\n",
    "        self.file_list = file_list\n",
    "        self.df = df_meta\n",
    "        # print(f\"filelist {len(self.file_list)}, df {self.df.shape}\")\n",
    "        assert len(self.file_list.keys()) == self.df.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(\"go to here\", idx)\n",
    "        print(\"df \", self.df.shape)\n",
    "        isic_id = self.df.loc[idx,\"isic_id\"]\n",
    "        target = self.df.loc[idx,\"target\"]        \n",
    "        img_path = self.file_list[isic_id]\n",
    "        # print(f\"isic_id {isic_id}. target {target}, path {img_path}\")\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "\n",
    "        return img, img_path, target\n",
    "class ISICDatasetTest(Dataset):\n",
    "    def __init__(self, df_meta, file_list, transform=None, n=\"all\"):        \n",
    "        self.file_list = file_list\n",
    "        self.df = df_meta\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        isic_id = self.df.loc[idx,\"isic_id\"]\n",
    "        img_path = self.file_list[isic_id]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "\n",
    "        return img\n",
    "\n",
    "def read_images_from_hdf5_and_save(file_path, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        ids_list = list(file.keys())        \n",
    "        ids_paths = {}\n",
    "        for img_id in tqdm(ids_list):\n",
    "            image_data = file[img_id][()]\n",
    "            image_path = os.path.join(output_dir, f\"{img_id}.png\")  # Define how you want to save the file\n",
    "            if os.path.exists(image_path):\n",
    "                ids_paths[img_id] = image_path\n",
    "                continue\n",
    "            # Save the image data to a file\n",
    "            with Image.open(io.BytesIO(image_data)) as image:\n",
    "                image.save(image_path)\n",
    "\n",
    "            # Store the path instead of the image data\n",
    "            ids_paths[img_id] = image_path\n",
    "    return ids_paths\n",
    "\n",
    "## 2. DEFINE MODEL -----------------------------------------------------------\n",
    "IMG_SIZE=224\n",
    "BATCH_SIZE=32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_model(model_name=\"efficientnet_v2_m\"):\n",
    "    if model_name == \"mobilenet_v3_small\":\n",
    "    # mobile net\n",
    "        model = models.mobilenet_v3_small()\n",
    "        model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, 1)\n",
    "    if model_name == \"efficientnet_v2_m\":\n",
    "        model = models.efficientnet_v2_m(weights=None)\n",
    "        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 1)\n",
    "    if model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=None)\n",
    "        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 1)\n",
    "\n",
    "    if model_name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 1)        \n",
    "    \n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    return model, optimizer, criterion\n",
    "\n",
    "## 3. DEFINE METRICS -------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "def compute_pauc(y_true, y_scores, tpr_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compute the partial AUC above a given TPR threshold.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): True binary labels.\n",
    "    y_scores (np.array): Target scores.\n",
    "    tpr_threshold (float): TPR threshold above which to compute the pAUC.\n",
    "    Returns:\n",
    "    float: The partial AUC above the given TPR threshold.\n",
    "    \"\"\"\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    # Find the indices where the TPR is above the threshold\n",
    "    tpr_above_threshold_indices = np.where(tpr >= tpr_threshold)[0]\n",
    "    if len(tpr_above_threshold_indices) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Extract the indices for the ROC segment above the threshold\n",
    "    start_index = tpr_above_threshold_indices[0] \n",
    "    fpr_above_threshold = fpr[start_index:]\n",
    "    tpr_above_threshold = tpr[start_index:] - tpr_threshold\n",
    "    partial_auc = auc(fpr_above_threshold, tpr_above_threshold)    \n",
    "    return partial_auc\n",
    "\n",
    "## 4. LOAD DATASET -------------------------------------------------------\n",
    "class PATHS:\n",
    "    train_images_h5_path = f\"{PRO_DIR}/input/train-image.hdf5\"\n",
    "    test_images_h5_path = f\"{PRO_DIR}/input/test-image.hdf5\"    \n",
    "    train_metadata_path = f\"{PRO_DIR}/input/train-metadata.csv\"\n",
    "    test_metadata_path = f\"{PRO_DIR}/input/test-metadata.csv\"    \n",
    "    submission_path = f\"{PRO_DIR}/input/sample_submission.csv\"\n",
    "    train_metadata_path_ext = f\"{PRO_DIR}/data/external/metadata.csv\"\n",
    "\n",
    "# # get more 2000 malignant data from external dataset\n",
    "df_meta = pd.read_csv(PATHS.train_metadata_path)[[\"isic_id\",\"patient_id\",\"target\"]]\n",
    "df_meta[\"set\"] = \"org\"\n",
    "\n",
    "df_meta_ext = pd.read_csv(PATHS.train_metadata_path_ext)\n",
    "df_meta_ext = df_meta_ext.loc[df_meta_ext[\"benign_malignant\"]==\"malignant\",[\"isic_id\",\"patient_id\",\"benign_malignant\"]]\n",
    "df_meta_ext = df_meta_ext.loc[(df_meta_ext[\"benign_malignant\"]==\"malignant\")&(~df_meta_ext[\"patient_id\"].isna())]\n",
    "df_meta_ext[\"benign_malignant\"] = 1\n",
    "df_meta_ext.rename(columns={\"benign_malignant\":\"target\"}, inplace=True)\n",
    "df_meta_ext[\"set\"]=\"ext\"\n",
    "df_meta_ext = df_meta_ext.sample(frac=1).sample(n=2000)\n",
    "\n",
    "meta_train = pd.concat([df_meta, df_meta_ext])\n",
    "meta_train[\"target\"]=meta_train[\"target\"].astype(\"int\")\n",
    "\n",
    "df_meta_pos = meta_train.loc[meta_train[\"target\"]==1]\n",
    "df_meta_neg = meta_train.loc[meta_train[\"target\"]==0].sample(frac=1).sample(n=len(df_meta_pos)*1, random_state=SEED)\n",
    "meta_train = pd.concat([df_meta_pos, df_meta_neg]).reset_index()\n",
    "# meta_train = meta_train.set_index(\"index\")\n",
    "\n",
    "## 5. TRAIN MODEL ----------------------------------------------\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    all_targets = []\n",
    "    all_probs = []        \n",
    "\n",
    "    model.train()\n",
    "    for input,_, targets in train_loader:        \n",
    "        input = input.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        targets = targets.unsqueeze(1) # make the target [batch, 1]\n",
    "        targets = targets.float() # BCEWithLogitsLoss requires targets as float()\n",
    "        # print(f\"input shape {input.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(output).cpu().detach().numpy()\n",
    "        # predictions = (probs > 0.5)\n",
    "\n",
    "        all_targets.extend(targets.cpu().detach().numpy().flatten())\n",
    "        all_probs.extend(probs.flatten())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    pauc = compute_pauc(np.array(all_targets), np.array(all_probs))\n",
    "    return total_loss, pauc\n",
    "\n",
    "def val(model, val_loader, criterion):\n",
    "    total_loss= 0\n",
    "    all_targets = []\n",
    "    all_probs = []        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input, _, targets in val_loader:\n",
    "            input = input.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "            targets = targets.unsqueeze(1) # make the target [batch, 1]\n",
    "            targets = targets.float() # BCEWithLogitsLoss requires targets as float()\n",
    "\n",
    "            output = model(input)\n",
    "            val_loss = criterion(output, targets)\n",
    "            total_loss +=  val_loss.item()\n",
    "\n",
    "            sigmoid = torch.nn.Sigmoid()\n",
    "            probs = sigmoid(output).cpu().detach().numpy().flatten()\n",
    "            # predictions = (probs > 0.5)\n",
    "            \n",
    "            all_targets.extend(targets.cpu().detach().numpy().flatten())\n",
    "            all_probs.extend(probs)           \n",
    "    \n",
    "    # pauc = compute_pauc(all_targets, all_predictions)\n",
    "    print(f\"all_targets {len(all_targets)}, all_probs {len(all_probs)}\")\n",
    "    pauc = compute_pauc(np.array(all_targets), np.array(all_probs))\n",
    "    return total_loss, pauc, all_probs, all_targets\n",
    "\n",
    "def get_mean_std(df):\n",
    "    trn_dataset = CustomDataset(df,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.Resize((IMG_SIZE, IMG_SIZE)),            \n",
    "                                    transforms.ToTensor(),\n",
    "                                ])\n",
    "                            ) \n",
    "    train_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True) \n",
    "    mean = 0.0\n",
    "    for images, _,_ in train_loader:\n",
    "        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)        \n",
    "        images = images.view(batch_samples, images.size(1), -1)  # print(images.shape) # will be (64, 3, 224x224)\n",
    "        mean += images.mean(2).sum(0)  \n",
    "    mean = mean / len(train_loader.dataset)\n",
    "\n",
    "    var = 0.0\n",
    "    for images, _,_ in train_loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        var += ((images - mean.unsqueeze(1))**2).sum([0,2])\n",
    "    std = torch.sqrt(var / (len(train_loader.dataset)*IMG_SIZE*IMG_SIZE))\n",
    "    return mean, std\n",
    "\n",
    "EXP_ID    = 3\n",
    "MODEL_NAME = \"efficientnet_v2_m\"\n",
    "NUM_EPOCHS = 30\n",
    "# BATCH_SIZE = 32\n",
    "NOTE=\"with_2k_external_db\"\n",
    "EXP_NAME = \"{:03}_{}_{}_{}_{}\".format(EXP_ID, MODEL_NAME, NUM_EPOCHS, BATCH_SIZE, NOTE)  # you can name your experiment whatever you like\n",
    "# SAVE_PATH = \"/kaggle/working\"\n",
    "SAVE_PATH = \"models\"\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s   %(levelname)s   %(message)s',\n",
    "                        level=logging.DEBUG,\n",
    "                        filename='{}.log'.format(EXP_NAME))\n",
    "\n",
    "TRAIN_CV = True\n",
    "if TRAIN_CV:\n",
    "    logging.info(f\"TRAIN CV ---------------------------------\")\n",
    "    from sklearn.model_selection import StratifiedKFold,GroupKFold\n",
    "    meta_train['group'] = meta_train['target'].astype(str) + \"_\" + meta_train['patient_id'].astype(str)\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "    \n",
    "\n",
    "    # train_data_stat = {}\n",
    "    # for i, (i_trn, i_val) in enumerate(cv.split(meta_train.drop(\"target\", axis=1), meta_train[\"target\"], groups=meta_train[\"group\"])):   \n",
    "    #     mean, std = get_mean_std(meta_train.loc[i_trn])        \n",
    "    #     train_data_stat[i] = {\"mean\": mean, \"std\": std}\n",
    "    #     logging.info(f\"fold {i}, mean {mean}, std {std}\")\n",
    "\n",
    "    train_data_stat ={\n",
    "        0: {\"mean\": [0.6822, 0.5201, 0.4416], \"std\":[0.1682, 0.1580, 0.1617]},\n",
    "        1: {\"mean\": [0.6863, 0.5066, 0.4145], \"std\":[0.1333, 0.1276, 0.1193]},\n",
    "        2: {\"mean\": [0.6831, 0.5211, 0.4434], \"std\":[0.1682, 0.1581, 0.1614]},\n",
    "        3: {\"mean\": [0.6855, 0.5224, 0.4436], \"std\":[0.1676, 0.1577, 0.1615]},\n",
    "        4: {\"mean\": [0.6840, 0.5217, 0.4445], \"std\":[0.1667, 0.1565, 0.1601]},\n",
    "    }\n",
    "        \n",
    "    for fold, (i_trn, i_val) in enumerate(cv.split(meta_train.drop(\"target\", axis=1), meta_train[\"target\"], groups=meta_train[\"patient_id\"])):\n",
    "        train_data_mean = train_data_stat[fold][\"mean\"]\n",
    "        train_data_std = train_data_stat[fold][\"std\"]\n",
    "        train_trans = transforms.Compose([    \n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),       \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=train_data_mean, std=train_data_std),\n",
    "        ])\n",
    "        val_trans =  transforms.Compose([    \n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),  \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=train_data_mean, std=train_data_std),\n",
    "        ])\n",
    "\n",
    "        trn_dataset = CustomDataset(\n",
    "            meta_train.loc[i_trn],\n",
    "            transform=train_trans\n",
    "        )\n",
    "        val_dataset = CustomDataset(\n",
    "            meta_train.loc[i_val],\n",
    "            transform=val_trans\n",
    "        )\n",
    "        \n",
    "        # Now, you can create separate data loaders for each split:\n",
    "        train_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        logging.info(f\"Fold {fold}, train {len(trn_dataset)}, val {len(val_dataset)}\")\n",
    "        model, optimizer, criterion = load_model(\"efficientnet_v2_m\")\n",
    "\n",
    "        best_val_loss, best_val_pauc = 100, 0        \n",
    "        for epoch in range(30):\n",
    "            train_loss, train_pauc = train(model, train_loader, optimizer, criterion)\n",
    "            val_loss, val_pauc, all_probs, all_targets = val(model, val_loader, criterion)        \n",
    "            if val_pauc > best_val_pauc:\n",
    "                best_val_pauc = val_pauc\n",
    "                os.makedirs(f\"{SAVE_PATH}/{EXP_NAME}\", exist_ok=True)            \n",
    "                torch.save(model.state_dict(),f\"{SAVE_PATH}/{EXP_NAME}/best_{fold}.pth\")\n",
    "                logging.info(f\"Epoch {epoch}, train_loss {train_loss:.4f}, train_pauc {train_pauc:.2f}, val_loss {val_loss:.4f}, val_pauc {val_pauc:.2f} --> Best val_pauc {val_pauc:.2f} at epoch {epoch}\")    \n",
    "            else:        \n",
    "                logging.info(f\"Epoch {epoch}, train_loss {train_loss:.4f}, train_pauc {train_pauc:.2f}, val_loss {val_loss:.4f}, val_pauc {val_pauc:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>set</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, isic_id, patient_id, target, set, group]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = meta_train.loc[i_trn]\n",
    "x.loc[x[\"patient_id\"]==\"IP_7198665\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 4782, 4783, 4785])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>set</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387</td>\n",
       "      <td>ISIC_0082829</td>\n",
       "      <td>IP_3249371</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_3249371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>935</td>\n",
       "      <td>ISIC_0096034</td>\n",
       "      <td>IP_6723298</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_6723298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245</td>\n",
       "      <td>ISIC_0104229</td>\n",
       "      <td>IP_9057861</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_9057861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1846</td>\n",
       "      <td>ISIC_0119495</td>\n",
       "      <td>IP_6856511</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_6856511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4812</td>\n",
       "      <td>ISIC_0190307</td>\n",
       "      <td>IP_4890448</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_4890448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>57198</td>\n",
       "      <td>ISIC_1484996</td>\n",
       "      <td>IP_7797815</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_7797815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>137288</td>\n",
       "      <td>ISIC_3477875</td>\n",
       "      <td>IP_0294957</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_0294957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>46771</td>\n",
       "      <td>ISIC_1226780</td>\n",
       "      <td>IP_6598006</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_6598006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>236260</td>\n",
       "      <td>ISIC_5939194</td>\n",
       "      <td>IP_2023739</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_2023739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>236727</td>\n",
       "      <td>ISIC_5951790</td>\n",
       "      <td>IP_6187331</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_6187331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3828 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       isic_id  patient_id  target  set         group\n",
       "0        387  ISIC_0082829  IP_3249371       1  org  1_IP_3249371\n",
       "1        935  ISIC_0096034  IP_6723298       1  org  1_IP_6723298\n",
       "2       1245  ISIC_0104229  IP_9057861       1  org  1_IP_9057861\n",
       "3       1846  ISIC_0119495  IP_6856511       1  org  1_IP_6856511\n",
       "5       4812  ISIC_0190307  IP_4890448       1  org  1_IP_4890448\n",
       "...      ...           ...         ...     ...  ...           ...\n",
       "4780   57198  ISIC_1484996  IP_7797815       0  org  0_IP_7797815\n",
       "4781  137288  ISIC_3477875  IP_0294957       0  org  0_IP_0294957\n",
       "4782   46771  ISIC_1226780  IP_6598006       0  org  0_IP_6598006\n",
       "4783  236260  ISIC_5939194  IP_2023739       0  org  0_IP_2023739\n",
       "4785  236727  ISIC_5951790  IP_6187331       0  org  0_IP_6187331\n",
       "\n",
       "[3828 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.loc[i_trn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>set</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>355693</td>\n",
       "      <td>ISIC_8881221</td>\n",
       "      <td>IP_7198665</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_7198665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       isic_id  patient_id  target  set         group\n",
       "2523  355693  ISIC_8881221  IP_7198665       0  org  0_IP_7198665"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = meta_train.loc[i_val]\n",
    "val.loc[val[\"patient_id\"]==\"IP_7198665\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ISIC_8299496'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trn_dataset\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mshape, trn_dataset\u001b[39m.\u001b[39;49mfile_list[\u001b[39m\"\u001b[39;49m\u001b[39mISIC_8299496\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ISIC_8299496'"
     ]
    }
   ],
   "source": [
    "trn_dataset.df.shape, trn_dataset.file_list[\"ISIC_8299496\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958, 6),\n",
       " '/home/kenny/Projects/kaggle/isic2024/input/train-image/image/ISIC_8299496.jpg')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val_dataset.df.shape, val_dataset.file_list[\"ISIC_8299496\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               355693\n",
       "isic_id       ISIC_8881221\n",
       "patient_id      IP_7198665\n",
       "target                   0\n",
       "set                    org\n",
       "group         0_IP_7198665\n",
       "Name: 2523, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.df.loc[2523]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6617/498562960.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta = pd.read_csv(PATHS.train_metadata_path)[[\"isic_id\",\"patient_id\",\"target\"]]\n",
      "/tmp/ipykernel_6617/498562960.py:5: DtypeWarning: Columns (8,13,16,17,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta_ext = pd.read_csv(PATHS.train_metadata_path_ext)\n"
     ]
    }
   ],
   "source": [
    "# # get more 2000 malignant data from external dataset\n",
    "df_meta = pd.read_csv(PATHS.train_metadata_path)[[\"isic_id\",\"patient_id\",\"target\"]]\n",
    "df_meta[\"set\"] = \"org\"\n",
    "\n",
    "df_meta_ext = pd.read_csv(PATHS.train_metadata_path_ext)\n",
    "df_meta_ext = df_meta_ext.loc[df_meta_ext[\"benign_malignant\"]==\"malignant\",[\"isic_id\",\"patient_id\",\"benign_malignant\"]]\n",
    "df_meta_ext = df_meta_ext.loc[(df_meta_ext[\"benign_malignant\"]==\"malignant\")&(~df_meta_ext[\"patient_id\"].isna())]\n",
    "df_meta_ext[\"benign_malignant\"] = 1\n",
    "df_meta_ext.rename(columns={\"benign_malignant\":\"target\"}, inplace=True)\n",
    "df_meta_ext[\"set\"]=\"ext\"\n",
    "df_meta_ext = df_meta_ext.sample(frac=1).sample(n=2000)\n",
    "\n",
    "meta_train = pd.concat([df_meta, df_meta_ext])\n",
    "meta_train[\"target\"]=meta_train[\"target\"].astype(\"int\")\n",
    "\n",
    "df_meta_pos = meta_train.loc[meta_train[\"target\"]==1]\n",
    "df_meta_neg = meta_train.loc[meta_train[\"target\"]==0].sample(frac=1).sample(n=len(df_meta_pos)*1, random_state=SEED)\n",
    "# meta_train = pd.concat([df_meta_pos, df_meta_neg]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train = pd.concat([df_meta_pos, df_meta_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['index'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6617/2597560664.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6118\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['index'] are in the columns\""
     ]
    }
   ],
   "source": [
    "meta_train = meta_train.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>ISIC_0082829</td>\n",
       "      <td>IP_3249371</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>ISIC_0096034</td>\n",
       "      <td>IP_6723298</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>ISIC_0104229</td>\n",
       "      <td>IP_9057861</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>ISIC_0119495</td>\n",
       "      <td>IP_6856511</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>ISIC_0157834</td>\n",
       "      <td>IP_3927284</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154579</th>\n",
       "      <td>ISIC_3906966</td>\n",
       "      <td>IP_8672132</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247118</th>\n",
       "      <td>ISIC_6209201</td>\n",
       "      <td>IP_6613669</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116536</th>\n",
       "      <td>ISIC_2962560</td>\n",
       "      <td>IP_9175987</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319341</th>\n",
       "      <td>ISIC_7983182</td>\n",
       "      <td>IP_1959951</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103385</th>\n",
       "      <td>ISIC_2635387</td>\n",
       "      <td>IP_9025934</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4786 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isic_id  patient_id  target  set\n",
       "387     ISIC_0082829  IP_3249371       1  org\n",
       "935     ISIC_0096034  IP_6723298       1  org\n",
       "1245    ISIC_0104229  IP_9057861       1  org\n",
       "1846    ISIC_0119495  IP_6856511       1  org\n",
       "3478    ISIC_0157834  IP_3927284       1  org\n",
       "...              ...         ...     ...  ...\n",
       "154579  ISIC_3906966  IP_8672132       0  org\n",
       "247118  ISIC_6209201  IP_6613669       0  org\n",
       "116536  ISIC_2962560  IP_9175987       0  org\n",
       "319341  ISIC_7983182  IP_1959951       0  org\n",
       "103385  ISIC_2635387  IP_9025934       0  org\n",
       "\n",
       "[4786 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, train 3828, val 958\n",
      "Fold 1, train 3829, val 957\n",
      "Fold 2, train 3829, val 957\n",
      "Fold 3, train 3829, val 957\n",
      "Fold 4, train 3829, val 957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_meta , undersample_rate=2, transform=None, n=\"all\"):   \n",
    "        file_list = {}\n",
    "        for _, row in df_meta.iterrows():        \n",
    "            if row[\"set\"]==\"org\":\n",
    "                file_list[row[\"isic_id\"]] = f\"{PRO_DIR}/input/train-image/image/{row['isic_id']}.jpg\"\n",
    "            else:\n",
    "                file_list[row[\"isic_id\"]] = f\"{PRO_DIR}/data/external/{row['isic_id']}.jpg\"\n",
    "        self.file_list = file_list\n",
    "        self.df = df_meta\n",
    "        # print(f\"filelist {len(self.file_list)}, df {self.df.shape}\")\n",
    "        assert len(self.file_list.keys()) == self.df.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        isic_id = self.df.loc[idx,\"isic_id\"]\n",
    "        target = self.df.loc[idx,\"target\"]        \n",
    "        img_path = self.file_list[isic_id]\n",
    "        # print(f\"isic_id {isic_id}. target {target}, path {img_path}\")\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "\n",
    "        return img, img_path, target\n",
    "cv = GroupKFold(n_splits=5)    \n",
    "for fold, (i_trn, i_val) in enumerate(cv.split(meta_train.drop(\"target\", axis=1), meta_train[\"target\"], groups=meta_train[\"patient_id\"])):\n",
    "    train_data_mean = [0.6822, 0.5201, 0.4416]\n",
    "    train_data_std = [0.1682, 0.1580, 0.1617]\n",
    "\n",
    "    trn_dataset = CustomDataset(meta_train.loc[i_trn])\n",
    "    val_dataset = CustomDataset(meta_train.loc[i_val])\n",
    "    \n",
    "    # Now, you can create separate data loaders for each split:\n",
    "    train_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"Fold {fold}, train {len(trn_dataset)}, val {len(val_dataset)}\")\n",
    "    input, _, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3828, 6), (958, 6))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.loc[i_trn].shape, meta_train.loc[i_val].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go to here 247\n",
      "df  (3828, 6)\n",
      "go to here 3555\n",
      "df  (3828, 6)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3555",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3555",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39minput\u001b[39m, _, target \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X31sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgo to here\u001b[39m\u001b[39m\"\u001b[39m, idx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X31sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdf \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X31sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m isic_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mloc[idx,\u001b[39m\"\u001b[39;49m\u001b[39misic_id\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X31sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mloc[idx,\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]        \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kenny/Projects/kaggle/isic2024/notebook/01.examine.ipynb#X31sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m img_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_list[isic_id]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(com\u001b[39m.\u001b[39mapply_if_callable(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_value(\u001b[39m*\u001b[39;49mkey, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n\u001b[1;32m   1184\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/pandas/core/frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4215\u001b[0m engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_engine\n\u001b[1;32m   4217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4218\u001b[0m     \u001b[39m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4219\u001b[0m     \u001b[39m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4220\u001b[0m     \u001b[39m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 4221\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(index)\n\u001b[1;32m   4222\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39m_values[row]\n\u001b[1;32m   4224\u001b[0m \u001b[39m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   4225\u001b[0m \u001b[39m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/isic2024-dOiDwEwf-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 3555"
     ]
    }
   ],
   "source": [
    "input, _, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               221943\n",
       "isic_id       ISIC_5580416\n",
       "patient_id      IP_5714646\n",
       "target                   0\n",
       "set                    org\n",
       "group         0_IP_5714646\n",
       "Name: 3555, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.df.loc[3555]\n",
    "# trn_dataset.df.loc[3555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = val_dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               221943\n",
       "isic_id       ISIC_5580416\n",
       "patient_id      IP_5714646\n",
       "target                   0\n",
       "set                    org\n",
       "group         0_IP_5714646\n",
       "Name: 3555, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.loc[3555,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3555 in i_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 4782, 4783, 4785])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   4,   24,   27,   45,   47,   49,   55,   60,   63,   66,\n",
       "       ...\n",
       "       4737, 4738, 4742, 4747, 4750, 4751, 4756, 4757, 4767, 4784],\n",
       "      dtype='int64', length=958)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>set</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387</td>\n",
       "      <td>ISIC_0082829</td>\n",
       "      <td>IP_3249371</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_3249371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>935</td>\n",
       "      <td>ISIC_0096034</td>\n",
       "      <td>IP_6723298</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_6723298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245</td>\n",
       "      <td>ISIC_0104229</td>\n",
       "      <td>IP_9057861</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_9057861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1846</td>\n",
       "      <td>ISIC_0119495</td>\n",
       "      <td>IP_6856511</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_6856511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4812</td>\n",
       "      <td>ISIC_0190307</td>\n",
       "      <td>IP_4890448</td>\n",
       "      <td>1</td>\n",
       "      <td>org</td>\n",
       "      <td>1_IP_4890448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>57198</td>\n",
       "      <td>ISIC_1484996</td>\n",
       "      <td>IP_7797815</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_7797815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>137288</td>\n",
       "      <td>ISIC_3477875</td>\n",
       "      <td>IP_0294957</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_0294957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>46771</td>\n",
       "      <td>ISIC_1226780</td>\n",
       "      <td>IP_6598006</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_6598006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>236260</td>\n",
       "      <td>ISIC_5939194</td>\n",
       "      <td>IP_2023739</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_2023739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>236727</td>\n",
       "      <td>ISIC_5951790</td>\n",
       "      <td>IP_6187331</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>0_IP_6187331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3828 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       isic_id  patient_id  target  set         group\n",
       "0        387  ISIC_0082829  IP_3249371       1  org  1_IP_3249371\n",
       "1        935  ISIC_0096034  IP_6723298       1  org  1_IP_6723298\n",
       "2       1245  ISIC_0104229  IP_9057861       1  org  1_IP_9057861\n",
       "3       1846  ISIC_0119495  IP_6856511       1  org  1_IP_6856511\n",
       "5       4812  ISIC_0190307  IP_4890448       1  org  1_IP_4890448\n",
       "...      ...           ...         ...     ...  ...           ...\n",
       "4780   57198  ISIC_1484996  IP_7797815       0  org  0_IP_7797815\n",
       "4781  137288  ISIC_3477875  IP_0294957       0  org  0_IP_0294957\n",
       "4782   46771  ISIC_1226780  IP_6598006       0  org  0_IP_6598006\n",
       "4783  236260  ISIC_5939194  IP_2023739       0  org  0_IP_2023739\n",
       "4785  236727  ISIC_5951790  IP_6187331       0  org  0_IP_6187331\n",
       "\n",
       "[3828 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.loc[i_trn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import sys\n",
    "# /kaggle/input/isic-pytorch-training-baseline/Final_model.bin\n",
    "BEST_WEIGHT = sys.argv[1]\n",
    "print(f\"BEST_WEIGHT = {BEST_WEIGHT}\")\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"img_size\": 256,\n",
    "    \"model_name\": \"edgenext_base.in21k_ft_in1k\",\n",
    "    \"valid_batch_size\": 32,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])\n",
    "ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "SAMPLE = f'{ROOT_DIR}/sample_submission.csv'\n",
    "\n",
    "# BEST_WEIGHT = \"/kaggle/input/isic-pytorch-training-baseline/Final_model.bin\"\n",
    "df = pd.read_csv(TEST_CSV)\n",
    "df['target'] = 0 # dummy\n",
    "df\n",
    "df_sub = pd.read_csv(SAMPLE)\n",
    "df_sub\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, df, file_hdf, transforms=None):\n",
    "        self.df = df\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.targets = df['target'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        isic_id = self.isic_ids[index]\n",
    "        img = np.array( Image.open(BytesIO(self.fp_hdf[isic_id][()])) )\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': img,\n",
    "            'target': target,\n",
    "        }\n",
    "train_data_mean=[0.6939, 0.5256, 0.4579]\n",
    "train_data_std=[0.1612, 0.1567, 0.1678]\n",
    "\n",
    "test_trans =  transforms.Compose([    \n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_data_mean, std=train_data_std),\n",
    "])\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
    "        self.isic_ids = isic_ids\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
    "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")    \n",
    "#         img = np.array(img)\n",
    "\n",
    "        if self.transform:\n",
    "#             transformed = self.transform(image=img)\n",
    "#             img = transformed['image']\n",
    "            img = self.transform(img)\n",
    "\n",
    "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        self.hdf5_file.close()  # Ensure file is closed when object is destroyed\n",
    "\n",
    "IMG_SIZE=224\n",
    "BATCH_SIZE=32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def load_one_model(model_name=\"efficientnet_v2_m\"):\n",
    "#     model = models.efficientnet_v2_m(weights=None)\n",
    "#     model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 1)\n",
    "#     model = model.to(DEVICE)\n",
    "#     return model, optimizer, criterion\n",
    "def load_models(folds):\n",
    "    cv_models = []\n",
    "    for fold in folds:\n",
    "        model = models.efficientnet_v2_m(weights=None)\n",
    "        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 1)\n",
    "        model = model.to(DEVICE)\n",
    "        model.load_state_dict(torch.load(BEST_WEIGHT, map_location=DEVICE))\n",
    "        model.eval()\n",
    "        cv_models.append(model)\n",
    "    return cv_models\n",
    "    \n",
    "cv_models = load_models(folds)\n",
    "df_sub[\"target\"] = preds\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isic2024-dOiDwEwf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
